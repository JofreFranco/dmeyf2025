{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test de Data Leakage en RandomForestFeaturesTransformer\n",
        "\n",
        "Este notebook reproduce el c√≥digo del RandomForestFeaturesTransformer y eval√∫a si hay data leakage calculando e imprimiendo:\n",
        "- Ganancia en el conjunto de entrenamiento\n",
        "- Ganancia en el conjunto de validaci√≥n\n",
        "\n",
        "Si la ganancia de validaci√≥n es muy alta o similar a la de entrenamiento (sin un modelo adicional entrenado), puede indicar data leakage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import logging\n",
        "from flaml.default import preprocess_and_suggest_hyperparams\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Definir constantes y par√°metros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constantes de ganancia\n",
        "GANANCIA_ACIERTO = 273000\n",
        "COSTO_ESTIMULO = 7000\n",
        "\n",
        "# Meses\n",
        "training_months = [202101, 202102]\n",
        "eval_month = 202104\n",
        "\n",
        "# Columnas a excluir\n",
        "exclude_cols = [\"numero_de_cliente\", \"label\", \"weight\", \"clase_ternaria\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Implementaci√≥n del RandomForestFeaturesTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        if \"clase_ternaria\" in X.columns:\n",
        "            raise ValueError(\"La columna 'clase_ternaria' no debe estar en el dataset\")\n",
        "        X_transformed = self._transform(X)\n",
        "        return X_transformed\n",
        "\n",
        "\n",
        "class RandomForestFeaturesTransformer(BaseTransformer):\n",
        "    def __init__(self, exclude_cols=[\"numero_de_cliente\", \"label\", \"weight\", \"clase_ternaria\"], \n",
        "                 n_estimators=20, num_leaves=16, min_data_in_leaf=100, \n",
        "                 feature_fraction_bynode=0.2, training_months=[], use_zero_shot=False):\n",
        "        self.exclude_cols = exclude_cols\n",
        "        self.training_months = training_months  \n",
        "        self.n_estimators = n_estimators\n",
        "        self.use_zero_shot = use_zero_shot\n",
        "        self.lgb_params = {\n",
        "            \"num_iterations\": n_estimators,\n",
        "            \"num_leaves\": num_leaves,\n",
        "            \"min_data_in_leaf\": min_data_in_leaf,\n",
        "            \"feature_fraction_bynode\": feature_fraction_bynode,\n",
        "            \"boosting\": \"rf\",\n",
        "            \"bagging_fraction\": (1.0 - 1.0 / np.exp(1.0)),\n",
        "            \"bagging_freq\": 1,\n",
        "            \"feature_fraction\": 1.0,\n",
        "            \"max_bin\": 31,\n",
        "            \"objective\": \"binary\",\n",
        "            \"first_metric_only\": True,\n",
        "            \"boost_from_average\": True,\n",
        "            \"feature_pre_filter\": False,\n",
        "            \"force_row_wise\": True,\n",
        "            \"verbosity\": -100,\n",
        "            \"max_depth\": -1,\n",
        "            \"min_gain_to_split\": 0.0,\n",
        "            \"min_sum_hessian_in_leaf\": 0.001,\n",
        "            \"lambda_l1\": 0.0,\n",
        "            \"lambda_l2\": 0.0,\n",
        "            \"pos_bagging_fraction\": 1.0,\n",
        "            \"neg_bagging_fraction\": 1.0,\n",
        "            \"is_unbalance\": False,\n",
        "            \"scale_pos_weight\": 1.0,\n",
        "            \"drop_rate\": 0.1,\n",
        "            \"max_drop\": 50,\n",
        "            \"skip_drop\": 0.5,\n",
        "            \"extra_trees\": False\n",
        "        }\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        logger.info(f\"Entrenando RandomForestFeaturesTransformer con {self.training_months} meses\")\n",
        "        X = X.copy()\n",
        "        X_train = X.loc[X[\"foto_mes\"].isin(self.training_months)]\n",
        "        y = X_train[\"label\"]\n",
        "        self.keep_cols = [col for col in X_train.columns if col not in self.exclude_cols]\n",
        "        X_train = X_train[self.keep_cols]\n",
        "        self.columns_ = X_train.columns\n",
        "        \n",
        "        if self.use_zero_shot:\n",
        "            (\n",
        "                hp,\n",
        "                estimator_class,\n",
        "                X_transformed,\n",
        "                y_transformed,\n",
        "                feature_transformer,\n",
        "                label_transformer,\n",
        "            ) = preprocess_and_suggest_hyperparams(\"classification\", X, y, \"rf\")\n",
        "            self.lgb_params.update({\n",
        "                \"num_iterations\": hp[\"n_estimators\"], \n",
        "                \"num_leaves\": hp[\"max_leaf_nodes\"], \n",
        "                \"feature_fraction\": hp[\"max_features\"]\n",
        "            })\n",
        "        \n",
        "        dtrain = lgb.Dataset(\n",
        "            data=X_train.values,\n",
        "            label=y,\n",
        "            free_raw_data=False\n",
        "        )\n",
        "        self.model_ = lgb.train(params=self.lgb_params, train_set=dtrain)\n",
        "        logger.info(\"RandomForestFeaturesTransformer entrenado\")\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def _transform(self, X):\n",
        "        X = X.copy()\n",
        "        extra_cols = set(X.columns) - set(self.keep_cols)\n",
        "        extra_cols = X[list(extra_cols)]\n",
        "        X = X[self.keep_cols]\n",
        "\n",
        "        prediccion = self.model_.predict(X.values, pred_leaf=True)\n",
        "        prediccion = np.array(prediccion, dtype=int)\n",
        "\n",
        "        n_obs, n_trees = prediccion.shape\n",
        "        logger.info(f\"Generando {n_trees} √°rboles de features...\")\n",
        "        new_cols = {}\n",
        "        for tree in range(n_trees):\n",
        "            leaves = np.unique(prediccion[:, tree])\n",
        "            for leaf in leaves:\n",
        "                varname = f\"rf_{tree + 1:03d}_{leaf:03d}\"\n",
        "                new_cols[varname] = (prediccion[:, tree] == leaf).astype(int)\n",
        "        \n",
        "        if new_cols:\n",
        "            logger.info(f\"Se generaron {len(new_cols)} nuevas columnas\")\n",
        "            new_cols_df = pd.DataFrame(new_cols, index=X.index)\n",
        "            X = pd.concat([X, new_cols_df, extra_cols], axis=1)\n",
        "        else:\n",
        "            logger.info(\"No se generaron nuevas columnas\")\n",
        "            X = pd.concat([X, extra_cols], axis=1)\n",
        "        \n",
        "        return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Funci√≥n para calcular ganancia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gan_eval(y_pred, weight, window=2001):\n",
        "    \"\"\"\n",
        "    Eval√∫a la ganancia m√°xima usando una media m√≥vil centrada con ventana de tama√±o `window`.\n",
        "    Retorna el mejor valor encontrado.\n",
        "    \"\"\"\n",
        "    ganancia = np.where(weight == 1.00002, GANANCIA_ACIERTO, 0) - np.where(weight < 1.00002, COSTO_ESTIMULO, 0)\n",
        "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
        "    ganancia = np.cumsum(ganancia)\n",
        "    \n",
        "    opt_sends = np.argmax(ganancia)\n",
        "    if opt_sends - (window-1)/2 < 0:\n",
        "        min_sends = 0\n",
        "    else:\n",
        "        min_sends = int(opt_sends - (window-1)/2)\n",
        "    if opt_sends + (window-1)/2 > len(ganancia):\n",
        "        max_sends = len(ganancia)\n",
        "    else:\n",
        "        max_sends = int(opt_sends + (window-1)/2)\n",
        "    \n",
        "    mean_ganancia = np.mean(ganancia[min_sends:max_sends])\n",
        "    \n",
        "    # Calcula la media m√≥vil centrada con la ventana especificada\n",
        "    ventana = window\n",
        "    pad = ventana // 2\n",
        "    ganancia_padded = np.pad(ganancia, (pad, ventana - pad - 1), mode='edge')\n",
        "    # Calcula la media m√≥vil centrada\n",
        "    medias_moviles = np.convolve(ganancia_padded, np.ones(ventana)/ventana, mode='valid')\n",
        "\n",
        "    # Obtiene el m√°ximo de la media m√≥vil centrada\n",
        "    mejor_ganancia = np.max(medias_moviles)\n",
        "    \n",
        "    return mejor_ganancia, mean_ganancia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cargar datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset\n",
        "df = pd.read_csv('data/competencia_01_target.csv')\n",
        "df = df.drop(columns=[\"mprestamos_personales\", \"cprestamos_personales\"])\n",
        "\n",
        "# Crear pesos y labels\n",
        "weight = {\"BAJA+1\": 1, \"BAJA+2\": 1.00002, \"CONTINUA\": 1}\n",
        "df[\"weight\"] = df[\"clase_ternaria\"].map(weight)\n",
        "df[\"label\"] = ((df[\"clase_ternaria\"] == \"BAJA+2\") | (df[\"clase_ternaria\"] == \"BAJA+1\")).astype(int)\n",
        "\n",
        "print(f\"Dataset cargado: {df.shape}\")\n",
        "print(f\"Meses disponibles: {sorted(df['foto_mes'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Preparar datos para entrenamiento y validaci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar solo los meses de entrenamiento y validaci√≥n\n",
        "df_work = df[df[\"foto_mes\"].isin(training_months + [eval_month])].copy()\n",
        "\n",
        "print(f\"\\nDatos de trabajo: {df_work.shape}\")\n",
        "print(f\"Meses de entrenamiento: {training_months}\")\n",
        "print(f\"Mes de validaci√≥n: {eval_month}\")\n",
        "print(f\"\\nDistribuci√≥n por mes:\")\n",
        "print(df_work.groupby('foto_mes').size())\n",
        "print(f\"\\nDistribuci√≥n de labels:\")\n",
        "print(df_work.groupby(['foto_mes', 'label']).size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Entrenar el RandomForestFeaturesTransformer\n",
        "\n",
        "**IMPORTANTE:** Este transformer entrena un Random Forest internamente usando SOLO los meses de training_months.\n",
        "Si hay data leakage, las features generadas tendr√°n informaci√≥n del futuro.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el transformer\n",
        "rf_transformer = RandomForestFeaturesTransformer(\n",
        "    exclude_cols=exclude_cols,\n",
        "    n_estimators=20,\n",
        "    num_leaves=16,\n",
        "    min_data_in_leaf=100,\n",
        "    feature_fraction_bynode=0.2,\n",
        "    training_months=training_months,\n",
        "    use_zero_shot=False\n",
        ")\n",
        "\n",
        "# Hacer fit del transformer con TODOS los datos (train + eval)\n",
        "# El transformer internamente filtrar√° por training_months\n",
        "rf_transformer.fit(df_work)\n",
        "\n",
        "print(\"\\nTransformer entrenado exitosamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Transformar datos y crear features\n",
        "\n",
        "Ahora aplicamos el transformer a los datos de entrenamiento y validaci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformar todos los datos\n",
        "df_transformed = rf_transformer.transform(df_work)\n",
        "\n",
        "print(f\"\\nDatos transformados: {df_transformed.shape}\")\n",
        "print(f\"Columnas originales: {df_work.shape[1]}\")\n",
        "print(f\"Nuevas columnas agregadas: {df_transformed.shape[1] - df_work.shape[1]}\")\n",
        "\n",
        "# Identificar las nuevas columnas de features RF\n",
        "rf_features = [col for col in df_transformed.columns if col.startswith('rf_')]\n",
        "print(f\"\\nTotal de features RF creadas: {len(rf_features)}\")\n",
        "print(f\"Ejemplos de features RF: {rf_features[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Separar train y validaci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar train y validaci√≥n\n",
        "df_train = df_transformed[df_transformed[\"foto_mes\"].isin(training_months)].copy()\n",
        "df_val = df_transformed[df_transformed[\"foto_mes\"] == eval_month].copy()\n",
        "\n",
        "print(f\"Train: {df_train.shape}\")\n",
        "print(f\"Validaci√≥n: {df_val.shape}\")\n",
        "\n",
        "# Extraer labels y weights\n",
        "y_train = df_train[\"label\"].values\n",
        "w_train = df_train[\"weight\"].values\n",
        "\n",
        "y_val = df_val[\"label\"].values\n",
        "w_val = df_val[\"weight\"].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Calcular \"predicciones\" usando solo las features RF\n",
        "\n",
        "**PRUEBA DE DATA LEAKAGE:**\n",
        "\n",
        "Si las features del Random Forest contienen data leakage, deber√≠an tener poder predictivo por s√≠ solas, incluso SIN entrenar un modelo adicional.\n",
        "\n",
        "Vamos a calcular una \"predicci√≥n\" simple sumando los valores de las features RF (todas son 0 o 1). Si hay leakage, esta suma deber√≠a correlacionar fuertemente con el target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usar las features RF como \"score\" de predicci√≥n\n",
        "# Simplemente sumamos todas las features RF (que son 0/1)\n",
        "# Si hay leakage, esta suma deber√≠a tener poder predictivo\n",
        "\n",
        "rf_score_train = df_train[rf_features].sum(axis=1).values\n",
        "rf_score_val = df_val[rf_features].sum(axis=1).values\n",
        "\n",
        "print(\"\\n=== AN√ÅLISIS DESCRIPTIVO ===\")\n",
        "print(f\"\\nScore RF Train - Min: {rf_score_train.min()}, Max: {rf_score_train.max()}, Mean: {rf_score_train.mean():.2f}\")\n",
        "print(f\"Score RF Val - Min: {rf_score_val.min()}, Max: {rf_score_val.max()}, Mean: {rf_score_val.mean():.2f}\")\n",
        "\n",
        "# Correlaci√≥n con el target\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "corr_train_pearson, p_train_pearson = pearsonr(rf_score_train, y_train)\n",
        "corr_val_pearson, p_val_pearson = pearsonr(rf_score_val, y_val)\n",
        "\n",
        "corr_train_spearman, p_train_spearman = spearmanr(rf_score_train, y_train)\n",
        "corr_val_spearman, p_val_spearman = spearmanr(rf_score_val, y_val)\n",
        "\n",
        "print(\"\\n=== CORRELACI√ìN CON EL TARGET ===\")\n",
        "print(f\"\\nTrain - Pearson: {corr_train_pearson:.4f} (p={p_train_pearson:.4e})\")\n",
        "print(f\"Val - Pearson: {corr_val_pearson:.4f} (p={p_val_pearson:.4e})\")\n",
        "print(f\"\\nTrain - Spearman: {corr_train_spearman:.4f} (p={p_train_spearman:.4e})\")\n",
        "print(f\"Val - Spearman: {corr_val_spearman:.4f} (p={p_val_spearman:.4e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Calcular ganancia usando las features RF directamente\n",
        "\n",
        "**PRUEBA CLAVE DE DATA LEAKAGE:**\n",
        "\n",
        "Vamos a calcular la ganancia usando SOLO el score RF (suma de features RF) sin entrenar ning√∫n modelo adicional.\n",
        "\n",
        "- Si obtenemos una ganancia significativa en VALIDACI√ìN sin haber entrenado un modelo predictivo, eso es una SE√ëAL FUERTE de data leakage.\n",
        "- Las features RF por s√≠ solas NO deber√≠an tener poder predictivo en datos futuros, a menos que contengan informaci√≥n del futuro.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular ganancia en TRAIN usando solo las features RF\n",
        "ganancia_train, mean_ganancia_train = gan_eval(rf_score_train, w_train, window=2001)\n",
        "\n",
        "# Calcular ganancia en VALIDACI√ìN usando solo las features RF\n",
        "ganancia_val, mean_ganancia_val = gan_eval(rf_score_val, w_val, window=2001)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS DE GANANCIA - PRUEBA DE DATA LEAKAGE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANTE: Estas ganancias se calculan usando SOLO las features del Random Forest\")\n",
        "print(\"    SIN entrenar ning√∫n modelo adicional. Si las ganancias son altas, especialmente\")\n",
        "print(\"    en validaci√≥n, es una se√±al de DATA LEAKAGE.\\n\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"GANANCIA EN ENTRENAMIENTO (meses {training_months}):\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"  - Ganancia m√°xima (media m√≥vil): ${ganancia_train:,.2f}\")\n",
        "print(f\"  - Ganancia media: ${mean_ganancia_train:,.2f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"GANANCIA EN VALIDACI√ìN (mes {eval_month}):\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"  - Ganancia m√°xima (media m√≥vil): ${ganancia_val:,.2f}\")\n",
        "print(f\"  - Ganancia media: ${mean_ganancia_val:,.2f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"AN√ÅLISIS DE LEAKAGE:\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Ratio de ganancia val/train\n",
        "if ganancia_train > 0:\n",
        "    ratio_ganancia = ganancia_val / ganancia_train\n",
        "    print(f\"  - Ratio Ganancia Val/Train: {ratio_ganancia:.4f}\")\n",
        "    \n",
        "    if ratio_ganancia > 0.8:\n",
        "        print(\"\\n  üö® ALERTA ROJA: Ganancia de validaci√≥n muy alta respecto a train!\")\n",
        "        print(\"     Esto es una SE√ëAL FUERTE de data leakage.\")\n",
        "    elif ratio_ganancia > 0.5:\n",
        "        print(\"\\n  ‚ö†Ô∏è  ADVERTENCIA: Ganancia de validaci√≥n sospechosamente alta.\")\n",
        "        print(\"     Posible data leakage.\")\n",
        "    elif ganancia_val > 50000000:  # 50M\n",
        "        print(\"\\n  ‚ö†Ô∏è  ADVERTENCIA: Ganancia de validaci√≥n absoluta muy alta.\")\n",
        "        print(\"     Posible data leakage.\")\n",
        "    else:\n",
        "        print(\"\\n  ‚úÖ Las ganancias parecen razonables para features sin modelo adicional.\")\n",
        "        print(\"     No hay se√±ales evidentes de data leakage en esta prueba.\")\n",
        "else:\n",
        "    print(\"  - No se puede calcular el ratio (ganancia train = 0)\")\n",
        "    if ganancia_val > 50000000:  # 50M\n",
        "        print(\"\\n  üö® ALERTA: Ganancia de validaci√≥n alta con ganancia de train baja/cero.\")\n",
        "        print(\"     SE√ëAL FUERTE de data leakage.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. An√°lisis adicional: Distribuci√≥n de features RF por target\n",
        "\n",
        "Vamos a ver si las features RF tienen una distribuci√≥n diferente entre BAJA+2 y CONTINUA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== DISTRIBUCI√ìN DE SCORE RF POR TARGET ===\")\n",
        "\n",
        "# Train\n",
        "print(\"\\nENTRENAMIENTO:\")\n",
        "print(f\"Score RF promedio para target=0 (CONTINUA): {df_train[df_train['label']==0][rf_features].sum(axis=1).mean():.2f}\")\n",
        "print(f\"Score RF promedio para target=1 (BAJA+1/+2): {df_train[df_train['label']==1][rf_features].sum(axis=1).mean():.2f}\")\n",
        "\n",
        "# Val\n",
        "print(\"\\nVALIDACI√ìN:\")\n",
        "print(f\"Score RF promedio para target=0 (CONTINUA): {df_val[df_val['label']==0][rf_features].sum(axis=1).mean():.2f}\")\n",
        "print(f\"Score RF promedio para target=1 (BAJA+1/+2): {df_val[df_val['label']==1][rf_features].sum(axis=1).mean():.2f}\")\n",
        "\n",
        "# T-test para ver si hay diferencia significativa\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "score_train_0 = df_train[df_train['label']==0][rf_features].sum(axis=1)\n",
        "score_train_1 = df_train[df_train['label']==1][rf_features].sum(axis=1)\n",
        "t_stat_train, p_value_train = ttest_ind(score_train_0, score_train_1)\n",
        "\n",
        "score_val_0 = df_val[df_val['label']==0][rf_features].sum(axis=1)\n",
        "score_val_1 = df_val[df_val['label']==1][rf_features].sum(axis=1)\n",
        "t_stat_val, p_value_val = ttest_ind(score_val_0, score_val_1)\n",
        "\n",
        "print(\"\\n=== T-TEST (diferencia entre target=0 y target=1) ===\")\n",
        "print(f\"\\nTrain: t-statistic={t_stat_train:.4f}, p-value={p_value_train:.4e}\")\n",
        "print(f\"Val: t-statistic={t_stat_val:.4f}, p-value={p_value_val:.4e}\")\n",
        "\n",
        "if p_value_val < 0.001:\n",
        "    print(\"\\n‚ö†Ô∏è  Las features RF muestran diferencias SIGNIFICATIVAS entre target=0 y target=1\")\n",
        "    print(\"   en el conjunto de validaci√≥n. Esto podr√≠a indicar:\")\n",
        "    print(\"   1. Las features capturan patrones √∫tiles (bueno)\")\n",
        "    print(\"   2. O contienen data leakage (malo)\")\n",
        "    print(\"   La ganancia calculada arriba ayuda a determinar cu√°l es el caso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Conclusiones\n",
        "\n",
        "### ¬øC√≥mo interpretar los resultados?\n",
        "\n",
        "**SIN Data Leakage esperar√≠amos:**\n",
        "- Ganancia de validaci√≥n BAJA o cercana a 0 usando solo las features RF\n",
        "- Baja correlaci√≥n entre el score RF y el target en validaci√≥n\n",
        "- Las features RF por s√≠ solas NO deber√≠an predecir bien en meses futuros\n",
        "\n",
        "**CON Data Leakage ver√≠amos:**\n",
        "- Ganancia de validaci√≥n ALTA (> 50M o ratio val/train > 0.5)\n",
        "- Alta correlaci√≥n entre el score RF y el target en validaci√≥n\n",
        "- Las features RF tienen poder predictivo incluso sin entrenar un modelo adicional\n",
        "\n",
        "### Pr√≥ximos pasos:\n",
        "1. Si hay leakage: revisar c√≥mo se filtran los datos en el m√©todo `fit()` del transformer\n",
        "2. Verificar que NO se use informaci√≥n del mes de validaci√≥n al crear las features\n",
        "3. Verificar que el Random Forest interno se entrena SOLO con training_months\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

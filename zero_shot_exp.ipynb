{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frjofre/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "import lightgbm as lgb\n",
    "from flaml.default import preprocess_and_suggest_hyperparams\n",
    "import logging\n",
    "from dmeyf2025.processors.feature_processors import CleanZerosTransformer, DeltaLagTransformer, PercentileTransformer, PeriodStatsTransformer, TendencyTransformer, IntraMonthTransformer, RandomForestFeaturesTransformer\n",
    "from dmeyf2025.metrics.revenue import GANANCIA_ACIERTO, COSTO_ESTIMULO\n",
    "\"\"\"import scipy.stats as stats\n",
    "if not hasattr(stats, 'binom_test'):\n",
    "    stats.binom_test = stats.binomtest  # parche compatibilidad\n",
    "    np.NaN = np.nan\"\"\"\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "debug_mode = False\n",
    "sampling_rate = 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b5a1c",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7df31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/competencia_01_target.csv')\n",
    "df = df.drop(columns=[\"mprestamos_personales\", \"cprestamos_personales\"])\n",
    "weight = {\"BAJA+1\": 1, \"BAJA+2\": 1.00002, \"CONTINUA\": 1}\n",
    "df[\"target\"] = ((df[\"clase_ternaria\"] == \"BAJA+2\") | (df[\"clase_ternaria\"] == \"BAJA+1\")).astype(int)\n",
    "\n",
    "training_months = [202101, 202102, 202103]\n",
    "eval_month = 202104\n",
    "test_month = 202106\n",
    "seeds = [537919, 923347, 173629, 419351, 287887, 1244, 24341, 1241, 4512, 6554, 62325, 6525235, 14, 4521, 474574, 74543, 32462, 12455, 5124, 55678]\n",
    "if debug_mode:\n",
    "    # Sample 0.5% of target=0 cases per month, keep all target=1 rows\n",
    "    df_list = []\n",
    "    for mes, df_mes in df[df[\"target\"] == 0].groupby(\"foto_mes\"):\n",
    "        df_sample = df_mes.sample(frac=0.005, random_state=42)\n",
    "        df_list.append(df_sample)\n",
    "    df_target_0_sampled = pd.concat(df_list, axis=0)\n",
    "    df_target_1 = df[df[\"target\"] == 1]\n",
    "    df = pd.concat([df_target_0_sampled, df_target_1], axis=0).reset_index(drop=True)\n",
    "    seeds = [42]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b20f0",
   "metadata": {},
   "source": [
    "# Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d4e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_eval(y_pred, weight, window=2001):\n",
    "    \"\"\"\n",
    "    Evalúa la ganancia máxima usando una media móvil centrada con ventana de tamaño `window`.\n",
    "    Retorna el mejor valor encontrado.\n",
    "    \"\"\"\n",
    "    ganancia = np.where(weight == 1.00002, GANANCIA_ACIERTO, 0) - np.where(weight < 1.00002, COSTO_ESTIMULO, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "    sends = np.argmax(ganancia)\n",
    "    opt_sends = np.argmax(ganancia)\n",
    "    if opt_sends - (window-1)/2 < 0:\n",
    "        min_sends = 0\n",
    "    else:\n",
    "        min_sends = int(opt_sends - (window-1)/2)\n",
    "    if opt_sends + (window-1)/2 > len(ganancia):\n",
    "        max_sends = len(ganancia)\n",
    "    else:\n",
    "        max_sends = int(opt_sends + (window-1)/2)\n",
    "    \n",
    "    mean_ganancia = np.mean(ganancia[min_sends:max_sends])\n",
    "    # Calcula la media móvil centrada con la ventana especificada\n",
    "    ventana = window\n",
    "    pad = ventana // 2\n",
    "    ganancia_padded = np.pad(ganancia, (pad, ventana - pad - 1), mode='edge')\n",
    "    # Calcula la media móvil centrada\n",
    "    medias_moviles = np.convolve(ganancia_padded, np.ones(ventana)/ventana, mode='valid')\n",
    "\n",
    "\n",
    "    # Obtiene el máximo de la media móvil centrada\n",
    "    mejor_ganancia = np.max(medias_moviles)\n",
    "    return mejor_ganancia, mean_ganancia\n",
    "def gan(X_val,\n",
    "    y_val,\n",
    "    estimator,\n",
    "    labels,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    weight_val=None,\n",
    "    weight_train=None,\n",
    "    *args,\n",
    "):  \n",
    "    y_pred = estimator.predict_proba(X_train)\n",
    "    ganancia_train, g_mean_train = gan_eval(y_pred, weight_train)\n",
    "    y_pred = estimator.predict(X_val)\n",
    "    ganancia_val, g_mean_val = gan_eval(y_pred, weight_val)\n",
    "    return -ganancia_val, {\"ganancia_val\": ganancia_val, \"ganancia_train\":ganancia_train, \"g_mean_train\":g_mean_train, \"g_mean_val\":g_mean_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec497f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval, save_model=True):\n",
    "    automl = AutoML()\n",
    "    # Entrenamiento\n",
    "    print(f\"Iniciando experimento {experiment_name}...\")\n",
    "    gains = []\n",
    "    times = []\n",
    "    for seed in seeds:\n",
    "        training_start_time = time.time()\n",
    "        settings[\"seed\"] = seed\n",
    "        (\n",
    "        hyperparams,\n",
    "        estimator_class,\n",
    "        X_transformed,\n",
    "        y_transformed,\n",
    "        feature_transformer,\n",
    "        label_transformer,\n",
    "        ) = preprocess_and_suggest_hyperparams(\"classification\", X_train, y_train, \"lgbm\")\n",
    "        model = estimator_class(**hyperparams, seed = seed)  # estimator_class is lightgbm.LGBMClassifier\n",
    "\n",
    "        model.fit(X_transformed, y_train)  # LGBMClassifier can handle raw labels\n",
    "        X_val = feature_transformer.transform(X_eval)  # preprocess test data\n",
    "        y_pred = model.predict_proba(X_val)[:,1]\n",
    "        rev = gan_eval(y_pred, w_eval, window=100)\n",
    "        training_end_time = time.time()\n",
    "        training_time = training_end_time - training_start_time\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(\"Ganancia:\", rev, \"Tiempo de entrenamiento:\", training_time)\n",
    "        gains.append(rev)\n",
    "        times.append(training_time)\n",
    "        # Prepare row data\n",
    "        result_row = {\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"gain\": rev,\n",
    "            \"seed\": seed,\n",
    "            \"training_time\": training_time,\n",
    "            \"hyperparameters\": repr(model.get_params())\n",
    "        }\n",
    "\n",
    "        write_header = not os.path.exists(results_file)\n",
    "        with open(results_file, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            if write_header:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(result_row)\n",
    "        if save_model:\n",
    "            joblib.dump(model, f\"models/{experiment_name}_{seed}.pkl\")\n",
    "            save_model = False\n",
    "    return np.mean(gains), np.sum(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c27f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmeyf2025.processors.sampler import SamplerProcessor\n",
    "\n",
    "def prepare_data(df, training_months, eval_month, test_month, get_features):\n",
    "    df[\"label\"] = ((df[\"clase_ternaria\"] == \"BAJA+2\") | (df[\"clase_ternaria\"] == \"BAJA+1\")).astype(int)\n",
    "    df[\"weight\"] = np.array([weight[item] for item in df[\"clase_ternaria\"]])\n",
    "    df = df.drop(columns=[\"clase_ternaria\"])\n",
    "    df_transformed = get_features(df, training_months)\n",
    "    df_train = df_transformed[df_transformed[\"foto_mes\"].isin(training_months)]\n",
    "    df_eval = df_transformed[df_transformed[\"foto_mes\"] == eval_month]\n",
    "    df_test = df_transformed[df_transformed[\"foto_mes\"] == test_month]\n",
    "\n",
    "    y_eval = df_eval[\"label\"]\n",
    "    w_eval = df_eval[\"weight\"]\n",
    "    X_eval = df_eval.drop(columns=[\"label\", \"weight\"])\n",
    "\n",
    "\n",
    "    y_test = df_test[\"label\"]\n",
    "    w_test = df_test[\"weight\"]\n",
    "    X_test = df_test.drop(columns=[\"label\", \"weight\"])\n",
    "\n",
    "    y_train = df_train[\"label\"]\n",
    "    X_train = df_train.drop(columns=[\"label\"])\n",
    "    X_train, y_train = SamplerProcessor(sampling_rate).fit_transform(X_train, y_train)\n",
    "    w_train = X_train[\"weight\"]\n",
    "    X_train = X_train.drop(columns=[\"weight\"])\n",
    "    return X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1368fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "settings = {\n",
    "    \"time_budget\": None,               # segundos\n",
    "    \"max_iter\": 0,\n",
    "    \"starting_points\": \"data\",        # Arrancamos con zero-shot\n",
    "    \"metric\": gan,                    # métrica custom\n",
    "    \"task\": \"classification\",         # binaria\n",
    "    \"estimator_list\": [\"lgbm\"],\n",
    "    \"log_file_name\": \"zero-shot.log\",\n",
    "    \"eval_method\": \"holdout\",         \n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "results_file = \"results.csv\"\n",
    "fieldnames = [\"experiment_name\", \"gain\", \"seed\", \"training_time\", \"hyperparameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8292c",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Lags y Delta Lags de orden 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8106e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_baseline\"\n",
    "def get_features(X, training_months):\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\", \"clase_ternaria\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbc1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c067493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_baseline...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(861326000.0), np.float64(852016969.6969697)) Tiempo de entrenamiento: 24.769181966781616\n",
      "Ganancia promedio: 856671484.8484849, Tiempo total: 24.769181966781616\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c4c28",
   "metadata": {},
   "source": [
    "# Zero-Clean\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Lags y Delta Lags de orden 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44feafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_zero_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15391f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cd82f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2738f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_zero_clean...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mean_rev, total_time = \u001b[43mzero_shot_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfieldnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGanancia promedio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_rev\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Tiempo total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mzero_shot_experiment\u001b[39m\u001b[34m(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval, save_model)\u001b[39m\n\u001b[32m      8\u001b[39m training_start_time = time.time()\n\u001b[32m      9\u001b[39m settings[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m] = seed\n\u001b[32m     10\u001b[39m (\n\u001b[32m     11\u001b[39m hyperparams,\n\u001b[32m     12\u001b[39m estimator_class,\n\u001b[32m     13\u001b[39m X_transformed,\n\u001b[32m     14\u001b[39m y_transformed,\n\u001b[32m     15\u001b[39m feature_transformer,\n\u001b[32m     16\u001b[39m label_transformer,\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m ) = \u001b[43mpreprocess_and_suggest_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlgbm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m model = estimator_class(**hyperparams, seed = seed)  \u001b[38;5;66;03m# estimator_class is lightgbm.LGBMClassifier\u001b[39;00m\n\u001b[32m     20\u001b[39m model.fit(X_transformed, y_train)  \u001b[38;5;66;03m# LGBMClassifier can handle raw labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/flaml/default/suggest.py:240\u001b[39m, in \u001b[36mpreprocess_and_suggest_hyperparams\u001b[39m\u001b[34m(task, X, y, estimator_or_predictor, location)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Preprocess the data and suggest hyperparameters.\u001b[39;00m\n\u001b[32m    193\u001b[39m \n\u001b[32m    194\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03m    label_transformer: a label transformer that can be applied to y_test.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m dt = DataTransformer()\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m X, y = \u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mchoose_xgb\u001b[39m\u001b[33m\"\u001b[39m == estimator_or_predictor:\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m# choose between xgb_limitdepth and xgboost\u001b[39;00m\n\u001b[32m    243\u001b[39m     estimator_or_predictor = suggest_learner(\n\u001b[32m    244\u001b[39m         task,\n\u001b[32m    245\u001b[39m         X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    248\u001b[39m         location=location,\n\u001b[32m    249\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/flaml/automl/data.py:314\u001b[39m, in \u001b[36mDataTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, task)\u001b[39m\n\u001b[32m    312\u001b[39m         cat_columns.append(column)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m X[column].nunique(dropna=\u001b[38;5;28;01mTrue\u001b[39;00m) < \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     drop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# datetime or numeric\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4891\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4888\u001b[39m     new_axis = axis.take(indexer)\n\u001b[32m   4890\u001b[39m bm_axis = \u001b[38;5;28mself\u001b[39m.ndim - axis_num - \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m4891\u001b[39m new_mgr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4894\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4897\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4899\u001b[39m result = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_mgr, axes=new_mgr.axes)\n\u001b[32m   4900\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:699\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRequested axis not found in manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     new_blocks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    706\u001b[39m     new_blocks = [\n\u001b[32m    707\u001b[39m         blk.take_nd(\n\u001b[32m    708\u001b[39m             indexer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    714\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    715\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:862\u001b[39m, in \u001b[36mBaseBlockManager._slice_take_blocks_ax0\u001b[39m\u001b[34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[39m\n\u001b[32m    860\u001b[39m                     blocks.append(nb)\n\u001b[32m    861\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m                 nb = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m                 blocks.append(nb)\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1373\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1370\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/array_algos/take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/core/array_algos/take.py:162\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[32m    165\u001b[39m     out = out.T\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a22e2",
   "metadata": {},
   "source": [
    "# Percentiles 5\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Lags y Delta Lags de orden 2\n",
    "- Percentiles discretizados en saltos de 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_percentiles_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    # Percentiles discretizados en saltos de 5\n",
    "    percentiles_transformer = PercentileTransformer(n_bins=5)\n",
    "    X_transformed = percentiles_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de percentiles transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8465cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_percentiles_5...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(846127000.0), np.float64(845755774.6478873)) Tiempo de entrenamiento: 35.675193786621094\n",
      "Ganancia promedio: 845941387.3239436, Tiempo total: 35.675193786621094\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")\n",
    "ganancia_intra_month_5 = mean_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08763853",
   "metadata": {},
   "source": [
    "# Percentiles 1\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Lags y Delta Lags de orden 2\n",
    "- Percentiles discretizados en saltos de 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_percentiles_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08756cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    # Percentiles discretizados en saltos de 1\n",
    "    percentiles_transformer = PercentileTransformer(n_bins=1)\n",
    "    X_transformed = percentiles_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de percentiles transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_percentiles_1...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(846103000.0), np.float64(845781194.0298507)) Tiempo de entrenamiento: 37.018494844436646\n",
      "Ganancia promedio: 845942097.0149254, Tiempo total: 37.018494844436646\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")\n",
    "ganancia_intra_month_1 = mean_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ce957",
   "metadata": {},
   "source": [
    "# Intra Month F.E\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Feature engineering intra mes\n",
    "- Lags y Delta Lags de orden 2\n",
    "- Percentiles discretizados en saltos de 1 o 5, el que de mejores resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb64b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_intra_month_fe\"\n",
    "n_bins = 5 if ganancia_intra_month_5 > ganancia_intra_month_1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f364749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    intra_month_transformer = IntraMonthTransformer()\n",
    "    X_transformed = intra_month_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de intra month transformer: {len(X_transformed.columns)}\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    # Percentiles discretizados en saltos de 5\n",
    "    percentiles_transformer = PercentileTransformer(n_bins=n_bins)\n",
    "    X_transformed = percentiles_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de percentiles transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b86603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_intra_month_fe...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(846055000.0), np.float64(845517027.027027)) Tiempo de entrenamiento: 36.579959869384766\n",
      "Ganancia promedio: 845786013.5135136, Tiempo total: 36.579959869384766\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f98d2a",
   "metadata": {},
   "source": [
    "# Historical\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Feature engineering intra mes\n",
    "- Lags y Delta Lags de orden 2\n",
    "- Tendencias\n",
    "- Stats de periodos\n",
    "- Percentiles discretizados en saltos de 1 o 5, el que de mejores resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89259f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_historical\"\n",
    "n_bins = 5 if ganancia_intra_month_5 > ganancia_intra_month_1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    initial_columns = X_transformed.columns\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    intra_month_transformer = IntraMonthTransformer()\n",
    "    X_transformed = intra_month_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de intra month transformer: {len(X_transformed.columns)}\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "    logger.info(\"Iniciando tendency transformer...\")\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "    tendency_transformer = TendencyTransformer(exclude_cols=[\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"] + list(new_columns))\n",
    "    X_transformed = tendency_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "\n",
    "    logger.info(f\"Cantidad de features después de tendency transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    logger.info(\"Iniciando period stats transformer...\")\n",
    "    period_stats_transformer = PeriodStatsTransformer(periods=[2, 3], exclude_cols=list(new_columns) + [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = period_stats_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "    logger.info(f\"Cantidad de features después de period stats transformer: {len(X_transformed.columns)}\")\n",
    "    # Percentiles discretizados en saltos de 5\n",
    "    percentiles_transformer = PercentileTransformer(n_bins=n_bins)\n",
    "    X_transformed = percentiles_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de percentiles transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_historical...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(846063000.0), np.float64(845657567.5675676)) Tiempo de entrenamiento: 65.5582070350647\n",
      "Ganancia promedio: 845860283.7837838, Tiempo total: 65.5582070350647\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702622b8",
   "metadata": {},
   "source": [
    "# Random Forest Features\n",
    "\n",
    "- Sacar prestamos personales\n",
    "- Pasar ceros a Nan en los casos que corresponda\n",
    "- Feature engineering intra mes\n",
    "- Lags y Delta Lags de orden 2\n",
    "- Tendencias\n",
    "- Stats de periodos\n",
    "- Percentiles discretizados en saltos de 1 o 5, el que de mejores resultados\n",
    "- Random Forest Features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75851c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"zero_shot_random_forest_features\"\n",
    "n_bins = 5 if ganancia_intra_month_5 > ganancia_intra_month_1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, training_months):\n",
    "    clean_zeros_transformer = CleanZerosTransformer()\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "    initial_columns = X_transformed.columns\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    intra_month_transformer = IntraMonthTransformer()\n",
    "    X_transformed = intra_month_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de intra month transformer: {len(X_transformed.columns)}\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols= [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "    logger.info(\"Iniciando tendency transformer...\")\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "    tendency_transformer = TendencyTransformer(exclude_cols=[\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"] + list(new_columns))\n",
    "    X_transformed = tendency_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "\n",
    "    logger.info(f\"Cantidad de features después de tendency transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    logger.info(\"Iniciando period stats transformer...\")\n",
    "    period_stats_transformer = PeriodStatsTransformer(periods=[2, 3], exclude_cols=list(new_columns) + [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = period_stats_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - set(initial_columns)\n",
    "    logger.info(f\"Cantidad de features después de period stats transformer: {len(X_transformed.columns)}\")\n",
    "    # Percentiles discretizados en saltos de 5\n",
    "    percentiles_transformer = PercentileTransformer(n_bins=n_bins)\n",
    "    X_transformed = percentiles_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de percentiles transformer: {len(X_transformed.columns)}\")\n",
    "    \n",
    "    logger.info(\"Iniciando RandomForest Feature Transformer...\")\n",
    "    random_forest_features_transformer = RandomForestFeaturesTransformer(training_months= training_months)  \n",
    "    X_transformed = random_forest_features_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features después de RandomForest Feature Transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_test, y_test = prepare_data(df, training_months, eval_month, test_month, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe150986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento zero_shot_random_forest_features...\n",
      "Seed: 42\n",
      "Ganancia: (np.float64(861346000.0), np.float64(853895555.5555556)) Tiempo de entrenamiento: 73.48208999633789\n",
      "Ganancia promedio: 857620777.7777778, Tiempo total: 73.48208999633789\n"
     ]
    }
   ],
   "source": [
    "mean_rev, total_time = zero_shot_experiment(experiment_name, seeds, results_file, fieldnames, settings, X_train, y_train, w_train, X_eval, y_eval, w_eval)\n",
    "print(f\"Ganancia promedio: {mean_rev}, Tiempo total: {total_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

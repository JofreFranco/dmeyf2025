{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a45302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frjofre/Documents/EyF/dmeyf2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from dmeyf2025.experiments import experiment_init, save_experiment_results\n",
    "from dmeyf2025.processors.feature_processors import CleanZerosTransformer, DeltaLagTransformer, PercentileTransformer, PeriodStatsTransformer, TendencyTransformer\n",
    "from dmeyf2025.utils.features_check import check_features\n",
    "from dmeyf2025.utils.data_dict import FINANCIAL_COLS\n",
    "from dmeyf2025.utils.wilcoxon import compare_with_best_model\n",
    "from dmeyf2025.utils.scale_params import scale_params\n",
    "from dmeyf2025.pipelines import load_data, preprocessing_pipeline, optimization_pipeline, evaluation_pipeline, production_pipeline\n",
    "\n",
    "FORCE_DEBUG = True\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8a0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X):\n",
    "    logger.info(f\"Cantidad de features: {len(X.columns)}\")\n",
    "    initial_columns = set(X.columns)\n",
    "\n",
    "    logger.info(\"Iniciando clean zeros transformer...\")\n",
    "    clean_zeros_transformer = CleanZerosTransformer(exclude_cols=[\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = clean_zeros_transformer.fit_transform(X)\n",
    "\n",
    "    logger.info(\"Iniciando tendency transformer...\")\n",
    "    tendency_transformer = TendencyTransformer(exclude_cols=[\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = tendency_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - initial_columns\n",
    "\n",
    "    logger.info(f\"Cantidad de features despu√©s de tendency transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    logger.info(\"Iniciando period stats transformer...\")\n",
    "    period_stats_transformer = PeriodStatsTransformer(periods=[2, 3], exclude_cols=list(new_columns) + [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = period_stats_transformer.fit_transform(X_transformed)\n",
    "    new_columns = set(X_transformed.columns) - initial_columns\n",
    "    logger.info(f\"Cantidad de features despu√©s de period stats transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    logger.info(\"Iniciando delta lag transformer...\")\n",
    "    delta_lag_transformer = DeltaLagTransformer(n_deltas=2, n_lags=2, exclude_cols=list(new_columns) + [\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"])\n",
    "    X_transformed = delta_lag_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features despu√©s de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    logger.info(\"Iniciando percentile transformer...\")\n",
    "    percentile_transformer = PercentileTransformer(variables=None, replace_original=True)\n",
    "    X_transformed = percentile_transformer.fit_transform(X_transformed)\n",
    "    logger.info(f\"Cantidad de features despu√©s de percentile transformer: {len(X_transformed.columns)}\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c109e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:23:40 | INFO | üöÄ INICIANDO EXPERIMENTO DEBUG_all_features EN MODO DEBUG\n",
      "18:23:40 | INFO | \n",
      "======================================================================\n",
      "üìÖ 2025-11-02 18:23:40\n",
      "üìù Iniciando experimento: DEBUG_all_features\n",
      "üéØ Descripci√≥n: test\n",
      "üîß Experiment folder: DEBUG_all_features_sr_0.1-t_70-mt_202010_202104-me_202106_1.0.0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Inicializar experimento\n",
    "experiment_config = experiment_init(\"config.yaml\", script_file=None, debug=FORCE_DEBUG)\n",
    "\n",
    "DEBUG = os.getenv('DEBUG_MODE', 'False').lower() == 'true'\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "seeds = experiment_config[\"seeds\"]\n",
    "\n",
    "np.random.seed(seeds[0])\n",
    "random.seed(seeds[0])\n",
    "\n",
    "# Logging inicial\n",
    "logger.info(\n",
    "    f\"\"\"\\n{'=' * 70}\n",
    "üìÖ {date_time}\n",
    "üìù Iniciando experimento: {experiment_config['experiment_name']}\n",
    "üéØ Descripci√≥n: {experiment_config['config']['experiment']['description']}\n",
    "üîß Experiment folder: {experiment_config['experiment_folder']}\n",
    "{'=' * 70}\"\"\"\n",
    ")\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c016e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:23:40 | INFO | Iniciando ETL pipeline...\n",
      "18:23:40 | INFO | Iniciando pipeline ETL completo...\n",
      "18:23:43 | INFO | Archivo le√≠do exitosamente: 978439 filas, 153 columnas, se eliminaron 2 columnas\n",
      "18:23:43 | INFO | Se filtraron 978439 filas, 153 columnas\n",
      "18:23:47 | INFO | Procesamiento completado: 978439 filas, 155 columnas\n",
      "18:23:47 | INFO | X shape: (978439, 154), y shape: (978439,)\n",
      "18:23:47 | INFO | Pipeline ETL completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(experiment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ae4dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:23:47 | INFO | Iniciando preprocessing pipeline...\n",
      "18:23:47 | INFO | Iniciando procesamiento de features...\n",
      "18:23:47 | INFO | Cantidad de features: 156\n",
      "18:23:47 | INFO | Iniciando clean zeros transformer...\n",
      "18:23:47 | INFO | Iniciando tendency transformer...\n",
      "18:23:56 | INFO | Cantidad de features despu√©s de tendency transformer: 201\n",
      "18:23:56 | INFO | Iniciando period stats transformer...\n",
      "18:23:56 | INFO | Cantidad de features despu√©s de period stats transformer: 561\n",
      "18:23:56 | INFO | Iniciando delta lag transformer...\n",
      "18:23:58 | INFO | Cantidad de features despu√©s de delta lag transformer: 1121\n",
      "18:23:58 | INFO | Iniciando percentile transformer...\n",
      "18:24:04 | INFO | Cantidad de features despu√©s de percentile transformer: 1121\n",
      "18:24:04 | INFO | Iniciando split de datos...\n",
      "18:24:04 | INFO | X_train.shape: (48631, 1119)\n",
      "18:24:05 | INFO | X_eval.shape: (16382, 1119)\n",
      "18:24:05 | INFO | X_prod.shape: (16315, 1118)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Pipeline\n",
    "X_train, y_train, w_train, X_eval, y_eval, w_eval, X_prod, y_prod, w_prod = preprocessing_pipeline(X, y, experiment_config, get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811adcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFO | X_train.shape: (16382, 1119)\n",
    "INFO | X_prod.shape: (16315, 1118)\n",
    "set(X_train.columns) - set(X_prod.columns)\n",
    "set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21cf0540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4586\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns.duplicated().sum(), X_train.index.duplicated().sum())\n",
    "print(X_prod.columns.duplicated().sum(), X_prod.index.duplicated().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

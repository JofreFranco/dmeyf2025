{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727bf1ac-8899-4406-b8b6-3162e124314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "import joblib\n",
    "import psutil\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from dmeyf2025.processors.feature_processors import CleanZerosTransformer, DeltaLagTransformer, PercentileTransformer, PeriodStatsTransformer, TendencyTransformer, IntraMonthTransformer, RandomForestFeaturesTransformer, DatesTransformer, HistoricalFeaturesTransformer, AddCanaritos\n",
    "\n",
    "from dmeyf2025.metrics.revenue import gan_eval\n",
    "from dmeyf2025.etl.etl import prepare_data\n",
    "pd.set_option('display.max_columns', None)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Para mostrar en consola\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3409e7b-ff96-440b-a26b-3ec9888adce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 02:30:17,315 - root - INFO - comenzando\n"
     ]
    }
   ],
   "source": [
    "# Algunos settings\n",
    "VERBOSE = False\n",
    "experiment_name = \"zlgbm-baseline\"\n",
    "training_months = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "       202101, 202102, 202103, 202104]\n",
    "save_model = True\n",
    "eval_month = 202106\n",
    "test_month = 202108\n",
    "seeds = [537919, 923347, 173629, 419351, 287887, 1244, 24341, 1241, 4512, 6554, 62325, 6525235, 14, 4521, 474574, 74543, 32462, 12455, 5124, 55678]\n",
    "debug_mode = False\n",
    "sampling_rate = 0.05\n",
    "results_file = \"/home/martin232009/buckets/b1/results.csv\"\n",
    "fieldnames = [\"experiment_name\", \"seed\", \"training_time\", \"moving_average_rev\"]\n",
    "logging.info(\"comenzando\")\n",
    "features_to_drop = [\"cprestamos_prendarios\", \"mprestamos_prendarios\", \"cprestamos_personales\", \"mprestamos_personales\"]\n",
    "canaritos = 10\n",
    "gradient_bound = 0.01\n",
    "n_seeds = 5\n",
    "params = {\n",
    "    \"canaritos\": canaritos,\n",
    "    \"gradient_bound\": gradient_bound,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "}\n",
    "\n",
    "experiment_name = f\"{experiment_name}_c{canaritos}_gb{experiment_name}_s{sampling_rate}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b1f69a-bce7-4ba2-820c-e6eb7ac2e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_gb(df: pd.DataFrame) -> float:\n",
    "    return df.memory_usage().sum() / (1024 ** 3)\n",
    "\n",
    "def apply_transformer(transformer, X, name: str, logger):\n",
    "    logger.info(f\"[{name}] Iniciando…\")\n",
    "\n",
    "    start_mem = memory_gb(X)\n",
    "    start_time = time.time()\n",
    "\n",
    "    Xt = transformer.fit_transform(X)\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = memory_gb(Xt)\n",
    "\n",
    "    n_rows, n_cols = Xt.shape\n",
    "\n",
    "    logger.info(\n",
    "        f\"[{name}] Tiempo: {end_time - start_time:.2f}s | \"\n",
    "        f\"Memoria antes: {start_mem:.3f} GB | \"\n",
    "        f\"Memoria después: {end_mem:.3f} GB | \"\n",
    "        f\"Diferencia: {end_mem - start_mem:+.3f} GB | \"\n",
    "        f\"Shape: {n_rows:,} filas × {n_cols:,} columnas\"\n",
    "    )\n",
    "    if VERBOSE:\n",
    "        display(Xt.head())\n",
    "        display(Xt.describe())\n",
    "        logger.info(f\"Nulos: {Xt.isna().astype(int).sum()}\")\n",
    "    gc.collect()\n",
    "    return Xt\n",
    "\n",
    "\n",
    "def get_features(X, training_months):\n",
    "\n",
    "    X_transformed = X\n",
    "\n",
    "    X_transformed = apply_transformer(\n",
    "        CleanZerosTransformer(),\n",
    "        X_transformed,\n",
    "        \"CleanZerosTransformer\",\n",
    "        logger\n",
    "    )\n",
    "\n",
    "    X_transformed = apply_transformer(\n",
    "        DeltaLagTransformer(\n",
    "            n_lags=2,\n",
    "            exclude_cols=[\"foto_mes\",\"numero_de_cliente\",\"target\",\"label\",\"weight\",\"clase_ternaria\"]\n",
    "        ),\n",
    "        X_transformed,\n",
    "        \"DeltaLagTransformer\",\n",
    "        logger\n",
    "    )\n",
    "    logger.info(f\"Cantidad de features después de delta lag transformer: {len(X_transformed.columns)}\")\n",
    "\n",
    "    X_transformed = apply_transformer(\n",
    "        PercentileTransformer(\n",
    "            replace_original=True\n",
    "        ),\n",
    "        X_transformed,\n",
    "        \"PercentileTransformer\",\n",
    "        logger\n",
    "    )\n",
    "\n",
    "    return X_transformed\n",
    "\n",
    "\n",
    "\n",
    "def train_model(train_set, params):\n",
    "    \"\"\"\n",
    "    Entrena un modelo ZuperLightGBM (lgbm)\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Features de entrenamiento\n",
    "        y_train (pd.Series): Variable objetivo de entrenamiento\n",
    "        w_train (pd.Series): Weights\n",
    "        params (dict): diccionario que debe tener:\n",
    "            - 'semilla_primigenia'\n",
    "            - 'min_data_in_leaf'\n",
    "            - 'learning_rate'\n",
    "            - 'canaritos': maneja el overfitting mediante canaritos, cuando detecta un árbol cuyo primer split es un canarito lo mata.\n",
    "            - 'gradient_bound': bound para el gradiente es algo asi como un learning rate que va cambiando a medida que se va entrenando???.\n",
    "    \"\"\"\n",
    "    lgb_params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"None\",        # Para usar métrica custom\n",
    "        \"first_metric_only\": False,\n",
    "        \"boost_from_average\": True,\n",
    "        \"feature_pre_filter\": False,\n",
    "        \"force_row_wise\": True,\n",
    "        \"verbosity\": -100,\n",
    "        \"seed\": params[\"seed\"],\n",
    "\n",
    "        \"max_bin\": 31,\n",
    "        \"min_data_in_leaf\": params[\"min_data_in_leaf\"],\n",
    "\n",
    "        \"num_iterations\": 9999,\n",
    "        \"num_leaves\": 9999,\n",
    "        \"learning_rate\": 1,\n",
    "\n",
    "        \"feature_fraction\": params[\"feature_fraction\"],\n",
    "\n",
    "        # Hiperparámetros del Zuperlightgbm\n",
    "        \"canaritos\": params[\"canaritos\"],\n",
    "        \"gradient_bound\": params[\"gradient_bound\"],  \n",
    "    }\n",
    "\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        lgb_params,\n",
    "        train_set\n",
    "    )\n",
    "    return gbm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72287b0-e411-4e8b-a19e-ca82b79d8851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 02:30:40,241 - __main__ - INFO - Leyendo dataset\n"
     ]
    }
   ],
   "source": [
    "# Leer datos\n",
    "logger.info(\"Leyendo dataset\")\n",
    "df = pd.read_csv('~/datasets/competencia_02_target.csv')\n",
    "# Eliminar features que no se van a usar\n",
    "keep_cols = [col for col in df.columns if col not in features_to_drop]\n",
    "df = df[keep_cols]\n",
    "df = df[~df[\"foto_mes\"].isna()]\n",
    "# Agregar target y calcular weight\n",
    "weight = {\"BAJA+1\": 1, \"BAJA+2\": 1.00002, \"CONTINUA\": 1}\n",
    "df[\"target\"] = ((df[\"clase_ternaria\"] == \"BAJA+2\") | (df[\"clase_ternaria\"] == \"BAJA+1\")).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b7046bb-2c82-4304-99c2-c13ed96992db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from dmeyf2025.processors.feature_processors import BaseTransformer\n",
    "from dmeyf2025.utils.data_dict import ALL_CAT_COLS, EXCLUDE_COLS\n",
    "class TendencyTransformer(BaseTransformer):\n",
    "    \"\"\"\n",
    "    Calcula la pendiente de regresión lineal de cada variable numérica para cada cliente usando una ventana de 6 meses.\n",
    "    \"\"\"\n",
    "    def __init__(self, exclude_cols=[\"foto_mes\", \"numero_de_cliente\", \"target\", \"label\", \"weight\"]):\n",
    "        self.exclude_cols = exclude_cols\n",
    "        self.numeric_cols_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"X debe ser un pandas DataFrame\")\n",
    "\n",
    "        self.numeric_cols_ = [\n",
    "            col for col in X.columns\n",
    "            if col not in self.exclude_cols and col not in ALL_CAT_COLS and col.startswith('m')\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def _transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"X debe ser un pandas DataFrame\")\n",
    "    \n",
    "        X = X.sort_values(['numero_de_cliente', 'foto_mes'])\n",
    "        clientes = X['numero_de_cliente'].values\n",
    "        new_cols = {}\n",
    "    \n",
    "        # identificar bloques contiguos por cliente\n",
    "        _, start_idx, counts = np.unique(clientes, return_index=True, return_counts=True)\n",
    "    \n",
    "        window = 6  # ventana de 6 meses\n",
    "    \n",
    "        for col in self.numeric_cols_:\n",
    "            y_all = X[col].values.astype(float)\n",
    "            slope = np.full_like(y_all, np.nan, dtype=float)\n",
    "    \n",
    "            for s, n in zip(start_idx, counts):\n",
    "                y = y_all[s : s + n]\n",
    "    \n",
    "                for i in range(n):\n",
    "                    # índices de ventana\n",
    "                    start = max(0, i - window + 1)\n",
    "                    y_win = y[start : i + 1]\n",
    "    \n",
    "                    mask = np.isfinite(y_win)\n",
    "                    if mask.sum() < 2:\n",
    "                        continue\n",
    "    \n",
    "                    # regresión en la ventana\n",
    "                    y_valid = y_win[mask]\n",
    "                    x_valid = np.arange(len(y_win))[mask]\n",
    "    \n",
    "                    # pendiente\n",
    "                    cov = np.cov(x_valid, y_valid, bias=True)\n",
    "                    var_x = cov[0, 0]\n",
    "    \n",
    "                    if var_x == 0:\n",
    "                        sl = np.nan\n",
    "                    else:\n",
    "                        sl = cov[0, 1] / var_x\n",
    "    \n",
    "                    slope[s + i] = sl\n",
    "    \n",
    "            new_cols[f\"{col}_tendency_6m\"] = slope\n",
    "    \n",
    "        X_out = X.assign(**new_cols)\n",
    "        return X_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98efbd68-88c9-454d-9338-51a6eb23a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 04:26:11,868 - __main__ - INFO - [PeriodStats] Iniciando…\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_transformed = \u001b[43mapply_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43mTendencyTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclase_ternaria\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPeriodStats\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mapply_transformer\u001b[39m\u001b[34m(transformer, X, name, logger)\u001b[39m\n\u001b[32m      7\u001b[39m start_mem = memory_gb(X)\n\u001b[32m      8\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m Xt = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m end_time = time.time()\n\u001b[32m     13\u001b[39m end_mem = memory_gb(Xt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/sklearn/base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dmeyf2025/src/dmeyf2025/processors/feature_processors.py:42\u001b[39m, in \u001b[36mBaseTransformer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclase_ternaria\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m X.columns:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLa columna \u001b[39m\u001b[33m'\u001b[39m\u001b[33mclase_ternaria\u001b[39m\u001b[33m'\u001b[39m\u001b[33m no debe estar en el dataset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m X_transformed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X_transformed\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mTendencyTransformer._transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     52\u001b[39m x_valid = np.arange(\u001b[38;5;28mlen\u001b[39m(y_win))[mask]\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# pendiente\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m cov = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m var_x = cov[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m var_x == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:2890\u001b[39m, in \u001b[36mcov\u001b[39m\u001b[34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[39m\n\u001b[32m   2887\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2888\u001b[39m         w *= aweights\n\u001b[32m-> \u001b[39m\u001b[32m2890\u001b[39m avg, w_sum = \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2891\u001b[39m w_sum = w_sum[\u001b[32m0\u001b[39m]\n\u001b[32m   2893\u001b[39m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:562\u001b[39m, in \u001b[36maverage\u001b[39m\u001b[34m(a, axis, weights, returned, keepdims)\u001b[39m\n\u001b[32m    559\u001b[39m a = np.asanyarray(a)\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m     axis = \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_axis_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maxis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m np._NoValue:\n\u001b[32m    565\u001b[39m     \u001b[38;5;66;03m# Don't pass on the keepdims argument if one wasn't given.\u001b[39;00m\n\u001b[32m    566\u001b[39m     keepdims_kw = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/numpy/_core/numeric.py:1470\u001b[39m, in \u001b[36mnormalize_axis_tuple\u001b[39m\u001b[34m(axis, ndim, argname, allow_duplicate)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[32m   1469\u001b[39m axis = \u001b[38;5;28mtuple\u001b[39m(normalize_axis_index(ax, ndim, argname) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis)\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m) != \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n\u001b[32m   1472\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepeated axis in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` argument\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X_transformed = apply_transformer(\n",
    "        TendencyTransformer(),\n",
    "        df.drop(columns=[\"clase_ternaria\"]),\n",
    "        \"PeriodStats\",\n",
    "        logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab8e20-f1b2-4648-b211-8d49f8a8da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
